from __future__ import annotations
import io, os, requests
import matplotlib.pyplot as plt
import pandas as pd
import streamlit as st

API_URL = "http://127.0.0.1:8000"
DEFAULT_USER = os.getenv("UXT_USER", "admin")
DEFAULT_PASS = os.getenv("UXT_PASS", "admin")

st.set_page_config(page_title="UXT ‚Äî Text Analysis System", page_icon="üìÑ", layout="wide")
st.title("üìÑ UXT ‚Äî Upload ‚Üí Chunk ‚Üí Analyze")

# ‚Äî‚Äî‚Äî –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –¥–æ API
st.sidebar.header("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è")
user = st.sidebar.text_input("–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á", DEFAULT_USER)
password = st.sidebar.text_input("–ü–∞—Ä–æ–ª—å", DEFAULT_PASS, type="password")
auth = (user, password)

# ‚Äî‚Äî‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —á–∞–Ω–∫—ñ–Ω–≥—É
chunk_size = st.sidebar.number_input("Chunk size", 100, 4000, 800, 50)
overlap = st.sidebar.number_input("Overlap", 0, 1000, 100, 10)
comment = st.sidebar.text_input("–ö–æ–º–µ–Ω—Ç–∞—Ä (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)", placeholder="–Ω–∞–ø—Ä., –õ–∞–±–∏ / PDF-—Å–∫–∞–Ω–∏")

# ‚Äî‚Äî‚Äî –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤ ‚Üí –ø—Ä–æ–≥—ñ–Ω —á–µ—Ä–µ–∑ API
uploaded = st.file_uploader("Upload PDF / DOCX / HTML", type=["pdf","docx","html","htm"], accept_multiple_files=True)
if uploaded and st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –ø—Ä–æ–≥—ñ–Ω —á–µ—Ä–µ–∑ API"):
    with st.spinner("–û–±—Ä–æ–±–∫–∞..."):
        files = [("files", (f.name, f.getvalue(), "application/octet-stream")) for f in uploaded]
        r = requests.post(f"{API_URL}/runs", auth=auth, data={"chunk_size": chunk_size, "overlap": overlap, "comment": comment}, files=files)
    if r.ok:
        st.success(f"‚úÖ Run —Å—Ç–≤–æ—Ä–µ–Ω–æ: {r.json()['id']} | —á–∞–Ω–∫—ñ–≤: {r.json()['chunks']}")
    else:
        st.error(f"‚ùå {r.status_code}: {r.text}")

st.write("---")
st.subheader("üóÇÔ∏è –Ü—Å—Ç–æ—Ä—ñ—è –ø—Ä–æ–≥–æ–Ω—ñ–≤")

if st.button("üîÑ –û–Ω–æ–≤–∏—Ç–∏ —Å–ø–∏—Å–æ–∫"):
    r = requests.get(f"{API_URL}/runs", auth=auth)
    if r.ok:
        st.session_state["runs"] = pd.DataFrame(r.json())
    else:
        st.error(f"–ü–æ–º–∏–ª–∫–∞: {r.status_code} ‚Äî {r.text}")

runs_df = st.session_state.get("runs")
if runs_df is not None:
    st.dataframe(runs_df, use_container_width=True, hide_index=True)
    if not runs_df.empty:
        run_id = st.number_input("Run ID", int(runs_df["id"].min()), int(runs_df["id"].max()), int(runs_df["id"].iloc[0]), 1)
        c1, c2, c3 = st.columns(3)
        if c1.button("üìä –ü–æ–∫–∞–∑–∞—Ç–∏ —á–∞–Ω–∫–∏"):
            rr = requests.get(f"{API_URL}/runs/{run_id}/chunks", auth=auth)
            if rr.ok:
                df = pd.DataFrame(rr.json())
                st.dataframe(df, use_container_width=True, hide_index=True)
                fig, ax = plt.subplots(); ax.hist(df["len_words"], bins=20); ax.set_title("Chunk length distribution"); st.pyplot(fig)
            else:
                st.error(f"–ü–æ–º–∏–ª–∫–∞: {rr.status_code}")

        if c2.button("üóëÔ∏è –í–∏–¥–∞–ª–∏—Ç–∏ Run"):
            requests.delete(f"{API_URL}/runs/{run_id}", auth=auth)
            st.warning("–í–∏–¥–∞–ª–µ–Ω–æ. –ù–∞—Ç–∏—Å–Ω–∏ ¬´–û–Ω–æ–≤–∏—Ç–∏ —Å–ø–∏—Å–æ–∫¬ª.")
        if c3.button("‚¨áÔ∏è –ï–∫—Å–ø–æ—Ä—Ç CSV"):
            exp = requests.get(f"{API_URL}/runs/{run_id}/export.csv", auth=auth)
            if exp.ok:
                st.download_button("‚¨áÔ∏è Download CSV", data=exp.content, file_name=f"run_{run_id}.csv", mime="text/csv")
            else:
                st.error("–ù–µ –≤–¥–∞–ª–æ—Å—è –µ–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏.")

st.write("---")
st.subheader("üîé –ü–æ—à—É–∫ –ø–æ —á–∞–Ω–∫–∞—Ö (FTS5)")

q = st.text_input('–ó–∞–ø–∏—Ç (FTS5): –Ω–∞–ø—Ä. "neural network", learn*')
colA, colB = st.columns([1,1])
with colA:
    run_filter = st.number_input("–§—ñ–ª—å—Ç—Ä –∑–∞ Run ID (0 = –≤—Å—ñ)", min_value=0, value=0, step=1)
with colB:
    limit = st.number_input("–õ—ñ–º—ñ—Ç", min_value=1, max_value=1000, value=50, step=10)

if st.button("–®—É–∫–∞—Ç–∏"):
    params = {"q": q, "limit": int(limit)}
    if run_filter > 0:
        params["run_id"] = int(run_filter)
    sr = requests.get(f"{API_URL}/search", params=params, auth=auth)
    if sr.ok:
        res = pd.DataFrame(sr.json())
        if not res.empty:
            st.dataframe(res, use_container_width=True, hide_index=True)
        else:
            st.info("–ù—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
    else:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É: {sr.status_code} ‚Äî {sr.text}")
